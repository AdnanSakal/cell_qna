{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing all the things we need, but before that you need to download and install llama on your PC.**"
      ],
      "metadata": {
        "id": "UK657d0Gor7f"
      },
      "id": "UK657d0Gor7f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "357bd294-1612-4987-9cda-c94608b4a520",
      "metadata": {
        "id": "357bd294-1612-4987-9cda-c94608b4a520"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OllamaEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_ollama import ChatOllama\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the model**"
      ],
      "metadata": {
        "id": "tm_6Sm7OpOaw"
      },
      "id": "tm_6Sm7OpOaw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf53d1ef-e440-44fc-80a0-7834aa7ce9d9",
      "metadata": {
        "id": "bf53d1ef-e440-44fc-80a0-7834aa7ce9d9"
      },
      "outputs": [],
      "source": [
        "model = ChatOllama(\n",
        "    model = \"llama3.2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading our file which we will use to build out RAG system**"
      ],
      "metadata": {
        "id": "UJ_fCcgrpS2v"
      },
      "id": "UJ_fCcgrpS2v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3311e11a-94d6-49ed-9e42-dcbda9348ffd",
      "metadata": {
        "id": "3311e11a-94d6-49ed-9e42-dcbda9348ffd"
      },
      "outputs": [],
      "source": [
        "raw_doc = TextLoader(\"./main_data.txt\").load()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We're not going to use whole file when asking question so we want to split it, also that will give us huge benefit when we will build our vector database for finding similler thing in the whole file**  "
      ],
      "metadata": {
        "id": "KZlGBZsoppBe"
      },
      "id": "KZlGBZsoppBe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6b598fe-fac9-4f00-aa34-69f7f1ee5d87",
      "metadata": {
        "id": "f6b598fe-fac9-4f00-aa34-69f7f1ee5d87"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300,\n",
        "chunk_overlap = 20)\n",
        "document = text_splitter.split_documents(raw_doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "578b2179-8349-454d-bb9e-2326a7fdb161",
      "metadata": {
        "id": "578b2179-8349-454d-bb9e-2326a7fdb161",
        "outputId": "900756ff-c5c0-4b99-dd18-83a1cbdf7132"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(document)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We're gonna use embedding for finding similler word**"
      ],
      "metadata": {
        "id": "SlhHonW2qK4w"
      },
      "id": "SlhHonW2qK4w"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41d99c7b-4839-453c-884f-c205ef737741",
      "metadata": {
        "scrolled": true,
        "id": "41d99c7b-4839-453c-884f-c205ef737741"
      },
      "outputs": [],
      "source": [
        "oembed = OllamaEmbeddings(model = \"nomic-embed-text\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the vector database also using the embedding in i**t"
      ],
      "metadata": {
        "id": "yTiO9SznqViW"
      },
      "id": "yTiO9SznqViW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc08c9bb-b8f5-4476-8b3a-b7a63fe4b616",
      "metadata": {
        "id": "bc08c9bb-b8f5-4476-8b3a-b7a63fe4b616"
      },
      "outputs": [],
      "source": [
        "db = Chroma.from_documents(document,embedding = oembed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building our chat template it's like how we want our answer to be**"
      ],
      "metadata": {
        "id": "pZI1_XvGqmBn"
      },
      "id": "pZI1_XvGqmBn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22a940b4-a9c5-45a4-9eba-9dfef0fc8d1a",
      "metadata": {
        "id": "22a940b4-a9c5-45a4-9eba-9dfef0fc8d1a"
      },
      "outputs": [],
      "source": [
        "chat_template_ = \"\"\"\n",
        "Answer the question based on the following context:\n",
        "{context}\n",
        "question: {question}\n",
        "\"\"\"\n",
        "chat_template = ChatPromptTemplate.from_template(chat_template_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To retrive relavent chunk (split sentances that we made earlier) from the question. We make our retriver with the help of vector database that we build earlier**"
      ],
      "metadata": {
        "id": "pLWrdWdjrOet"
      },
      "id": "pLWrdWdjrOet"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "591ce4a7-1ac7-4e85-abe2-4e336798324a",
      "metadata": {
        "id": "591ce4a7-1ac7-4e85-abe2-4e336798324a"
      },
      "outputs": [],
      "source": [
        "retriver = db.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will make a function that will join all the chunk it(retriver) found similler**"
      ],
      "metadata": {
        "id": "OlxjGSwrr6JH"
      },
      "id": "OlxjGSwrr6JH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5bad5e2-cd32-4fc3-9e00-14111ac30715",
      "metadata": {
        "id": "e5bad5e2-cd32-4fc3-9e00-14111ac30715"
      },
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Making our chain or steps that the user input wiil go through**"
      ],
      "metadata": {
        "id": "G-OmOw8Tr__2"
      },
      "id": "G-OmOw8Tr__2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe7af34c-716a-44eb-a646-2182650751f5",
      "metadata": {
        "id": "fe7af34c-716a-44eb-a646-2182650751f5"
      },
      "outputs": [],
      "source": [
        "chain = ({\"context\":retriver|format_docs,\"question\":RunnablePassthrough()}|chat_template|model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finally we use this chain to get our answer**"
      ],
      "metadata": {
        "id": "eRk-FkMRsKHW"
      },
      "id": "eRk-FkMRsKHW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "997acbcc-6012-4ffc-8668-45e133c01769",
      "metadata": {
        "id": "997acbcc-6012-4ffc-8668-45e133c01769",
        "outputId": "600dedab-9cf8-445b-e5bd-c7cbe7a53064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "According to the context, the cell nucleus is:\n",
            "\n",
            "* The most conspicuous organelle found in a eukaryotic cell.\n",
            "* The information center of the cell.\n",
            "* The place where the cell's chromosomes are housed.\n"
          ]
        }
      ],
      "source": [
        "print(chain.invoke(\"what is cell nucleus\").content)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}